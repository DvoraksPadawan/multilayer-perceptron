{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import numpy as np\n\nclass MLP:\n    def __init__(self):\n        self.input_size = 2\n        self.hidden_size = 4\n        self.output_size = 1\n        \n        self.w1 = np.random.random((self.input_size, self.hidden_size))\n        self.w2 = np.random.random((self.hidden_size, self.output_size))\n        self.b1 = np.array([np.random.random() for TO in range(self.hidden_size)])\n        self.b2 = np.array([np.random.random() for TO in range(self.output_size)])\n        \n        self.ITERS = 100\n        self.LR = 0.1\n        self.alpha = 0.01\n\n    def predict(self, x, return_hidden_output=False):\n        hidden_input = self.forward(x, self.w1, self.b1)\n        hidden_output = self.relu(hidden_input)\n        if return_hidden_output:\n            return hidden_output\n        output_input = self.forward(hidden_output, self.w2, self.b2)\n        output = self.relu(output_input)\n        return output\n\n    def forward(self, l1, w, b):\n        l2 = np.dot(l1, w) + b\n        return l2\n\n    def train(self, X, Y):\n        for _ in range(self.ITERS):\n            for x, y in zip(X, Y):\n                self.backward(x, y)\n\n    def backward(self, x, y):\n        hidden_output = self.predict(x, return_hidden_output=True)\n        pred = self.predict(x)\n        \n        output_error = 2 * (pred - y) \n        hidden_error = np.dot(output_error, self.w2.T)\n        \n        w2_grad = hidden_output.T * output_error\n        h_grad = np.dot(hidden_output, hidden_error.T)\n        w1_grad = np.outer(x, h_grad)\n        \n        self.update_weights(self.w2, self.b2, w2_grad)\n        self.update_weights(self.w1, self.b1, w1_grad)\n\n    def update_weights(self, w, b, error):\n        print(error)\n        for FROM in range(w.shape[0]):\n            for TO in range(w.shape[1]):\n                w[FROM][TO] -= self.LR * error[FROM]\n                b[TO] -= self.LR * error[FROM]\n\n    def relu(self, x):\n        return np.where(x > 0, x, 0)\n\nX = np.array([\n    [0, 0],\n    [1, 0],\n    [0, 1],\n    [1, 1]\n])\nY = np.array([[0], [1], [1], [0]])\n\nmodel = MLP()\nmodel.train(X, Y)\n\n\na = model.predict([1, 0])\nprint(\"Prediction:\", a)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}